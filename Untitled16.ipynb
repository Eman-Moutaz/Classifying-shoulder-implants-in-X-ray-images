{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOIV9u4gmJlR"
      },
      "outputs": [],
      "source": [
        "!pip install tflearn\n",
        "!pip install ipympl\n",
        "import tflearn\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "from PIL import Image, ImageOps\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "# Set the right path to the data\n",
        "path_var_train = '/content/drive/MyDrive/ai_train/' \n",
        "#count the number of images in the folder\n",
        "path_train, dirs_train, files_train = next(os.walk(path_var_train))\n",
        "number_images_train = len(files_train)\n",
        "print(number_images_train)\n",
        "print(files_train)\n",
        "\n",
        "\n",
        "# Set the right path to the data\n",
        "path_var_tst = '/content/drive/MyDrive/ai_test/' \n",
        "#count the number of images in the folder\n",
        "path_tst, dirs_tst, files_tst = next(os.walk(path_var_tst))\n",
        "number_images_tst = len(files_tst)\n",
        "print(number_images_tst)\n",
        "files_tst\n",
        "\n",
        "\n",
        "MODEL_NAME = 'X_rays'\n",
        "IMG_SIZE = 224\n",
        "LR = 0.001\n",
        "def create_label(image_name):\n",
        "    \"\"\" Create an one-hot encoded vector from image name \"\"\"\n",
        "    label = image_name.split('.')[-3]\n",
        "    if label == 'Cofield':\n",
        "        return np.array([1,0,0,0])\n",
        "    elif label == 'Depuy':\n",
        "        return np.array([0,1,0,0])\n",
        "    elif label== 'Tornier':\n",
        "        return np.array([0,0,1,0])\n",
        "    elif label == 'Zimmer':\n",
        "        return np.array([0,0,0,1])\n",
        "\n",
        "\n",
        "def create_train_data():\n",
        "    training_data = []\n",
        "    for img in tqdm(os.listdir(path_var_train)):\n",
        "        path = os.path.join(path_var_train, img)\n",
        "        img_data = cv2.imread(path, 0)\n",
        "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "        training_data.append([np.array(img_data), create_label(img)])\n",
        "    shuffle(training_data)\n",
        "    np.save('train_data.npy', training_data)\n",
        "    return training_data\n",
        "\n",
        "def create_test_data():\n",
        "    testing_data= []\n",
        "    for img in tqdm(os.listdir(path_var_tst)):\n",
        "        path = os.path.join(path_var_tst, img)\n",
        "        img_data = cv2.imread(path, 0)\n",
        "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "        testing_data.append([np.array(img_data),create_label(img)])\n",
        "    shuffle(testing_data)\n",
        "    return testing_data       \n",
        "\n",
        "if (os.path.exists('train_data.npy')): # If you have already created the dataset:\n",
        "    train_data =np.load('train_data.npy',allow_pickle=True)\n",
        "    \n",
        "else: # If dataset is not created:\n",
        "    train_data = create_train_data()\n",
        "\n",
        "if (os.path.exists('test_data.npy')):\n",
        "    test_data =np.load('test_data.npy')\n",
        "else:\n",
        "    test_data = create_test_data()\n",
        "\n",
        "\n",
        "train = train_data\n",
        "X = np.array([i[0] for i in train]).reshape(-1, 224, 224, 1)\n",
        "Y = [i[1] for i in train]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20,shuffle=True)\n",
        "\n",
        "#tf.reset_default_graph()\n",
        "conv_input = input_data(shape=[None, 224, 224, 1], name='input')\n",
        "\n",
        "conv1 = conv_2d(conv_input, 32, 3, activation='relu')\n",
        "pool1 = max_pool_2d(conv1, 3)\n",
        "\n",
        "conv2 = conv_2d(pool1, 64, 3, activation='relu')\n",
        "pool2 = max_pool_2d(conv2, 3)\n",
        "\n",
        "conv3 = conv_2d(pool2, 128, 3, activation='relu')\n",
        "pool3 = max_pool_2d(conv3, 3)\n",
        "\n",
        "#conv4 = conv_2d(pool3, 256, 3, activation='relu')\n",
        "#pool4 = max_pool_2d(conv4, 3)\n",
        "\n",
        "fully_layer = fully_connected(pool3, 265, activation='relu')\n",
        "fully_layer = dropout(fully_layer, 0.5)\n",
        "cnn_layers = fully_connected(fully_layer, 4, activation='softmax')\n",
        "cnn_layers = regression(cnn_layers, optimizer='adam', learning_rate = LR, loss='categorical_crossentropy', name='targets')\n",
        "model = tflearn.DNN(cnn_layers, tensorboard_dir='log', tensorboard_verbose=3)\n",
        "print (X_train.shape)\n",
        "\n",
        "\n",
        "if (os.path.exists('model.tfl.meta')):\n",
        "    model.load('./model.tfl')\n",
        "else:\n",
        "    model.fit({'input': X_train}, {'targets': y_train}, n_epoch=10,\n",
        "              validation_set=({'input': X_test}, {'targets': y_test} ), snapshot_step=500, show_metric=True, run_id='X_rays')\n",
        "    model.save('model.tfl')\n",
        "\n",
        "x=cv2.imread('/content/drive/MyDrive/ai_test/Cofield.56.jpg')\n",
        "plt.hist(x)\n",
        "print(plt.show())   \n",
        "\n",
        "img = cv2.imread('',0)\n",
        "test_img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "test_img = test_img.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
        "prediction = model.predict([test_img])[0]\n",
        "prediction = model.predict(f\"Cofield: {prediction[1,0,0,0]} , Dupuy : {prediction[0,1,0,0]} , Zimmer : {prediction[0,0,1,0]} , Tornier: {prediction[0,0,0,1]}   \") \n",
        "print(prediction)"
      ]
    }
  ]
}